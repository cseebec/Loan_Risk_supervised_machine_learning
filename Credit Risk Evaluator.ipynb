{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from 2 CSV files. One will provide the training data and the other will provide the testing data\n",
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull X and y data from these dataframes\n",
    "X_train = train_df.drop([\"loan_status\"], axis=1)\n",
    "y_train = train_df[\"loan_status\"]\n",
    "X_test = test_df.drop([\"loan_status\"], axis=1)\n",
    "y_test = test_df[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure all data is Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>dti</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57107</td>\n",
       "      <td>57107</td>\n",
       "      <td>13375.0</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>483.34</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>223000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>29.99</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>577150.0</td>\n",
       "      <td>122018.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>170200.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141451</td>\n",
       "      <td>141451</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>478.68</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>123000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>11.26</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132750.0</td>\n",
       "      <td>27896.0</td>\n",
       "      <td>15900.0</td>\n",
       "      <td>35398.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321143</td>\n",
       "      <td>321143</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>448.95</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>197000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>11.28</td>\n",
       "      <td>...</td>\n",
       "      <td>85.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>628160.0</td>\n",
       "      <td>114043.0</td>\n",
       "      <td>22600.0</td>\n",
       "      <td>90340.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11778</td>\n",
       "      <td>11778</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>100.22</td>\n",
       "      <td>RENT</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>18.08</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42006.0</td>\n",
       "      <td>20761.0</td>\n",
       "      <td>19900.0</td>\n",
       "      <td>15406.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>169382</td>\n",
       "      <td>169382</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.1612</td>\n",
       "      <td>1056.49</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>27.77</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283248.0</td>\n",
       "      <td>109056.0</td>\n",
       "      <td>79500.0</td>\n",
       "      <td>58778.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   index  loan_amnt  int_rate  installment home_ownership  \\\n",
       "0       57107   57107    13375.0    0.1797       483.34       MORTGAGE   \n",
       "1      141451  141451    21000.0    0.1308       478.68       MORTGAGE   \n",
       "2      321143  321143    20000.0    0.1240       448.95       MORTGAGE   \n",
       "3       11778   11778     3000.0    0.1240       100.22           RENT   \n",
       "4      169382  169382    30000.0    0.1612      1056.49       MORTGAGE   \n",
       "\n",
       "   annual_inc verification_status pymnt_plan    dti  ...  pct_tl_nvr_dlq  \\\n",
       "0    223000.0        Not Verified          n  29.99  ...           100.0   \n",
       "1    123000.0     Source Verified          n  11.26  ...            85.0   \n",
       "2    197000.0     Source Verified          n  11.28  ...            85.7   \n",
       "3     45000.0        Not Verified          n  18.08  ...           100.0   \n",
       "4    133000.0     Source Verified          n  27.77  ...           100.0   \n",
       "\n",
       "   percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  \\\n",
       "0              50.0                   0.0        0.0         577150.0   \n",
       "1              33.3                   0.0        0.0         132750.0   \n",
       "2              33.3                   0.0        0.0         628160.0   \n",
       "3              16.7                   1.0        0.0          42006.0   \n",
       "4              66.7                   0.0        0.0         283248.0   \n",
       "\n",
       "   total_bal_ex_mort total_bc_limit  total_il_high_credit_limit  \\\n",
       "0           122018.0        32000.0                    170200.0   \n",
       "1            27896.0        15900.0                     35398.0   \n",
       "2           114043.0        22600.0                     90340.0   \n",
       "3            20761.0        19900.0                     15406.0   \n",
       "4           109056.0        79500.0                     58778.0   \n",
       "\n",
       "   hardship_flag  debt_settlement_flag  \n",
       "0              N                     N  \n",
       "1              N                     N  \n",
       "2              N                     N  \n",
       "3              N                     N  \n",
       "4              N                     N  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the first few rows of the X_train dataframe\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>dti</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67991</td>\n",
       "      <td>67991</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>814.70</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>19.75</td>\n",
       "      <td>...</td>\n",
       "      <td>97.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>527975.0</td>\n",
       "      <td>70914.0</td>\n",
       "      <td>74600.0</td>\n",
       "      <td>99475.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25429</td>\n",
       "      <td>25429</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>208.70</td>\n",
       "      <td>RENT</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>11.52</td>\n",
       "      <td>...</td>\n",
       "      <td>66.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34628.0</td>\n",
       "      <td>23460.0</td>\n",
       "      <td>5900.0</td>\n",
       "      <td>23628.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38496</td>\n",
       "      <td>38496</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>128.27</td>\n",
       "      <td>RENT</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>6.74</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23100.0</td>\n",
       "      <td>19183.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19667</td>\n",
       "      <td>19667</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>478.33</td>\n",
       "      <td>RENT</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>12.13</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56481.0</td>\n",
       "      <td>43817.0</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>35981.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37505</td>\n",
       "      <td>37505</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>120.27</td>\n",
       "      <td>RENT</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>n</td>\n",
       "      <td>16.08</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45977.0</td>\n",
       "      <td>32448.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>24977.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index  loan_amnt  int_rate  installment home_ownership  \\\n",
       "0       67991  67991    40000.0    0.0819       814.70       MORTGAGE   \n",
       "1       25429  25429     6000.0    0.1524       208.70           RENT   \n",
       "2       38496  38496     3600.0    0.1695       128.27           RENT   \n",
       "3       19667  19667    20000.0    0.1524       478.33           RENT   \n",
       "4       37505  37505     3600.0    0.1240       120.27           RENT   \n",
       "\n",
       "   annual_inc verification_status pymnt_plan    dti  ...  pct_tl_nvr_dlq  \\\n",
       "0    140000.0        Not Verified          n  19.75  ...            97.7   \n",
       "1     55000.0        Not Verified          n  11.52  ...            66.7   \n",
       "2     42000.0        Not Verified          n   6.74  ...           100.0   \n",
       "3    100000.0        Not Verified          n  12.13  ...           100.0   \n",
       "4     50000.0        Not Verified          n  16.08  ...           100.0   \n",
       "\n",
       "   percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  tot_hi_cred_lim  \\\n",
       "0               0.0                   0.0        0.0         527975.0   \n",
       "1               0.0                   0.0        0.0          34628.0   \n",
       "2               0.0                   0.0        0.0          23100.0   \n",
       "3              50.0                   0.0        0.0          56481.0   \n",
       "4              25.0                   0.0        0.0          45977.0   \n",
       "\n",
       "   total_bal_ex_mort total_bc_limit  total_il_high_credit_limit  \\\n",
       "0            70914.0        74600.0                     99475.0   \n",
       "1            23460.0         5900.0                     23628.0   \n",
       "2            19183.0         7300.0                     15000.0   \n",
       "3            43817.0        13800.0                     35981.0   \n",
       "4            32448.0        21000.0                     24977.0   \n",
       "\n",
       "   hardship_flag  debt_settlement_flag  \n",
       "0              N                     N  \n",
       "1              N                     N  \n",
       "2              N                     N  \n",
       "3              N                     N  \n",
       "4              N                     N  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the first few rows of the X_test dataframe\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that certain columns have strings as their values such as home_ownership. Python can only use numeric datatypes in regression so I need to convert these columns to numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies converts categorical columns into dummy/indicator columns\n",
    "X_train_dummies = pd.get_dummies(X_train)\n",
    "X_test_dummies = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <th>pymnt_plan_n</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <th>hardship_flag_N</th>\n",
       "      <th>hardship_flag_Y</th>\n",
       "      <th>debt_settlement_flag_N</th>\n",
       "      <th>debt_settlement_flag_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57107</td>\n",
       "      <td>57107</td>\n",
       "      <td>13375.0</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>483.34</td>\n",
       "      <td>223000.0</td>\n",
       "      <td>29.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141451</td>\n",
       "      <td>141451</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>478.68</td>\n",
       "      <td>123000.0</td>\n",
       "      <td>11.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321143</td>\n",
       "      <td>321143</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>448.95</td>\n",
       "      <td>197000.0</td>\n",
       "      <td>11.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   index  loan_amnt  int_rate  installment  annual_inc    dti  \\\n",
       "0       57107   57107    13375.0    0.1797       483.34    223000.0  29.99   \n",
       "1      141451  141451    21000.0    0.1308       478.68    123000.0  11.26   \n",
       "2      321143  321143    20000.0    0.1240       448.95    197000.0  11.28   \n",
       "\n",
       "   delinq_2yrs  inq_last_6mths  open_acc  ...  verification_status_Verified  \\\n",
       "0          0.0             0.0      15.0  ...                             0   \n",
       "1          2.0             0.0      16.0  ...                             0   \n",
       "2          0.0             0.0      12.0  ...                             0   \n",
       "\n",
       "   pymnt_plan_n  initial_list_status_f  initial_list_status_w  \\\n",
       "0             1                      0                      1   \n",
       "1             1                      0                      1   \n",
       "2             1                      0                      1   \n",
       "\n",
       "   application_type_Individual  application_type_Joint App  hardship_flag_N  \\\n",
       "0                            1                           0                1   \n",
       "1                            1                           0                1   \n",
       "2                            1                           0                1   \n",
       "\n",
       "   hardship_flag_Y  debt_settlement_flag_N  debt_settlement_flag_Y  \n",
       "0                0                       1                       0  \n",
       "1                0                       1                       0  \n",
       "2                0                       1                       0  \n",
       "\n",
       "[3 rows x 94 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is a sample of the train dummy data\n",
    "X_train_dummies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Sure the training and testing dataframes match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to train regression models using train_dummies_df and then test the model using test_dummies_df. So I need to make sure these dataframes have the same columns or else the regression models will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataframe has 94 columns. The testing dataframe has 93 columns\n"
     ]
    }
   ],
   "source": [
    "# Get all column headers from both dataframes and print the number of columns of each df\n",
    "training_columns = []\n",
    "for i in X_train_dummies.columns:\n",
    "    training_columns.append(i)\n",
    "\n",
    "testing_columns = []\n",
    "for i in X_test_dummies.columns:\n",
    "    testing_columns.append(i)\n",
    "\n",
    "print(f\"The training dataframe has {len(training_columns)} columns. The testing dataframe has {len(testing_columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['debt_settlement_flag_Y']\n"
     ]
    }
   ],
   "source": [
    "# Find any column headers that are in one data set but not in the other\n",
    "missing_headers = list(set(training_columns) - set(testing_columns))\n",
    "print(missing_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column to testing dataframe so it matches training dataframe. Since this column was not in the testing dataframe before I know all the values are 0\n",
    "X_test_dummies[missing_headers] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['high_risk', 'low_risk']\n"
     ]
    }
   ],
   "source": [
    "# Get a list of possible y categories\n",
    "myset = set(y_train)\n",
    "target_names = list(myset)\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Models\n",
    "In the next lines of code I am going to be comparing 2 models, a logistic regression and a random forests classifier, on how well they predict whether each loan will become high risk or not. \n",
    "\n",
    "Logistic regression (LR) is a classification algorithm used to predict a discrete set of classes or categories. LR uses the Sigmoid function to return a probability value of 0 or 1. \n",
    "\n",
    "Random Forests Classifier (RF) is also a classification algorith that returns a discrete set of classes or categories. However, unlike logistic regression, RF uses a collection of decision trees to make predictions. A decision trees is a question / test that has binary results it is either true or false. Decision trees can become very complex very quickly. This is why the Random Forests Classifier model uses several smaller decision trees. Each of these decision trees on its own its considered a weak classifier but when you combine them they form a strong classifier. \n",
    "\n",
    "## Comparison\n",
    "On average LR is faster\n",
    "LR is easier to understand\n",
    "RFC performs better for more categorical data\n",
    "LR performs better for linear data\n",
    "RFC is better for unbalanced data\n",
    "LR performs better when signal-to-noise is low (i.e. the problem is “hard” and there is little data)\n",
    "\n",
    "## Prediction: Random Forests Classifier will perform better\n",
    "I have not studied the data extensively, but I am assuming it will be more categorical than linear so I am going to guess that Random Forests Classifier will perform better than Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.648440065681445\n",
      "Testing Data Score: 0.5253083794130158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Collin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier\n",
    "classifier.fit(X_train_dummies, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {classifier.score(X_train_dummies, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_dummies, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 526, 1825],\n",
       "       [ 407, 1944]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a confusion matrix for the logistic regression model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = classifier.predict(X_test_dummies)\n",
    "confusion_matrix(y_true, y_pred, labels = target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.56      0.22      0.32      2351\n",
      "    low_risk       0.52      0.83      0.64      2351\n",
      "\n",
      "    accuracy                           0.53      4702\n",
      "   macro avg       0.54      0.53      0.48      4702\n",
      "weighted avg       0.54      0.53      0.48      4702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.6405784772437261\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=100).fit(X_train_dummies, y_train)\n",
    "\n",
    "print(f'Training Score: {clf.score(X_train_dummies, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_dummies, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 930, 1421],\n",
       "       [ 269, 2082]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a confusion matrix for the logistic regression model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test_dummies)\n",
    "confusion_matrix(y_true, y_pred, labels = target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.78      0.40      0.52      2351\n",
      "    low_risk       0.59      0.89      0.71      2351\n",
      "\n",
      "    accuracy                           0.64      4702\n",
      "   macro avg       0.68      0.64      0.62      4702\n",
      "weighted avg       0.68      0.64      0.62      4702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "#### Overall the Random Forests Classifier performed better than the Logistic Regression model. \n",
    "\n",
    "### Score\n",
    "\n",
    "First lets look at the training and testing scores of each model. Score means the R-squared value. R-squared is a common baseline metric for evaluating models because it shows how accurate the model is. So an R-squared score of 1 means the model is 100% accurate and a R-squared score of 0.50 means the model is 50% accurate. \n",
    "\n",
    "For each model I calculated 2 R-squared scores a training and a testing score. The models were created with training data so the training score shows how well the model fits the data that it was created with. The testing score shows how well the model predicts new data. \n",
    "\n",
    "The LR model had a training score of 0.648. This means that the LR model did not fit well to the data at all. On the other hand, the RF had a perfect 1 training score. This means it fit to the training data perfectly, which actually means it is probably overfit. \n",
    "\n",
    "The LR model had a testing score of 0.525 (52.5%). This is absolutlely terrible because it means that the model is only 2.5% more accurate than if you were to just flip a coin to predict the result. The RF had a testing score of 0.640 (64.0%). This testing score is still not great but it is significantly better than the logistic regression model. \n",
    "\n",
    "### Classification Report\n",
    "\n",
    "It also helps to look at additional metrics other than testing score to evaluate and compare the models. The testing score is just the overall accuracy of the model certain times you may want to be wrong about certain things to be safe rather than sorry. For example, in my opinion I would rather have this model predict a loan as high risk and the loan actually be low risk than to predict a loan as low risk when it is actually high risk. \n",
    "\n",
    "To see how accurate the models are in this area we will look at the classification reports. Precision is a measure of how reliable a classification is. Recall is a measure of the percentage of a classification that the model labelled / predicted correctly. \n",
    "\n",
    "The LR had a high risk Recall of 0.22 (22%) so out of all the high risk loans it only predicted around a fifth correctly. The RF had a high risk Recall of 0.35 (40%) so it predicted 4 out of 10 high-risk loans correctly which is significantly better than the LR model. \n",
    "\n",
    "The LR had a low risk Precision of 0.52 (52%) meaning when it predicts a loan is low risk it is correct 52% of the time. The RF had a low risk precision of 0.59 (59%).\n",
    "\n",
    "Overall the RF performed better than the LR in every important metric.\n",
    "\n",
    "\n",
    "## Prediction 2: Scaling the data \n",
    "In the first models I did not scale the data before fitting the models. I am going to re-fit the models using scaled data. I am confident the accuracy of both models will increase. Additionally I predict the Random Forests Classifier will still perform better than Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data and refit it\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train_dummies)\n",
    "X_train_scaled = scaler.transform(X_train_dummies)\n",
    "X_test_scaled = scaler.transform(X_test_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.713136288998358\n",
      "Testing Data Score: 0.7203317737133135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Collin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "classifier = LogisticRegression()\n",
    "classifier\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1243, 1108],\n",
       "       [ 207, 2144]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run a confusion matrix for the logistic regression model\n",
    "y_true = y_test\n",
    "y_pred = classifier.predict(X_test_scaled)\n",
    "confusion_matrix(y_true, y_pred, labels = target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.86      0.53      0.65      2351\n",
      "    low_risk       0.66      0.91      0.77      2351\n",
      "\n",
      "    accuracy                           0.72      4702\n",
      "   macro avg       0.76      0.72      0.71      4702\n",
      "weighted avg       0.76      0.72      0.71      4702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.6418545299872395\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=100).fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 936, 1415],\n",
       "       [ 269, 2082]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "confusion_matrix(y_true, y_pred, labels = target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   high_risk       0.78      0.40      0.53      2351\n",
      "    low_risk       0.60      0.89      0.71      2351\n",
      "\n",
      "    accuracy                           0.64      4702\n",
      "   macro avg       0.69      0.64      0.62      4702\n",
      "weighted avg       0.69      0.64      0.62      4702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before and After \n",
    "\n",
    "## Logistic Regression \n",
    "\n",
    "Training Score: 0.648 vs 0.713\n",
    "Testing Score: 0.525 vs  0.720\n",
    "Recall high-risk: 0.22 vs 0.53\n",
    "Precision low-risk: 0.52 vs 0.66\n",
    "\n",
    "## Random Forest Classifier \n",
    "\n",
    "Training Score: 1 vs 1\n",
    "Testing Score: 0.64 vs 0.64\n",
    "Recall high risk: 0.40 vs 0.40\n",
    "Precision low-risk: 0.59 vs 0.60\n",
    "    \n",
    "## Conclusions\n",
    "I was incorrect, both models did not improve by scaling the data. The Logistic Regression model improved when the data was scaled but the Random Forests Classifier data gave the same results.\n",
    "\n",
    "# Comparison\n",
    "\n",
    "## LR vs RF\n",
    "\n",
    "Training score: 0.713 vs 1 \n",
    "Conclusion: RF is still overfit\n",
    "----------------------------------------------\n",
    "Testing Score: 0.720 vs 0.64\n",
    "Winner: LR. LR was 8% more accurate overall\n",
    "-----------------------------------------------\n",
    "Recall high risk: 0.53 vs 0.40\n",
    "Winner: LR. LR predicted 13% more of the total high risk loans correctly. \n",
    "----------------------------------------------\n",
    "Precision low-risk: 0.66 vs 0.60\n",
    "Winner: LR. LR's prediction that a loan is low risk is 6% more reliable\n",
    "---------------------------------------------\n",
    "\n",
    "## Conclusion \n",
    "The LR model was the better model with scaled data. The RF data is still overfit though, so I am confident that if features were removed from the RF model if would become more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
